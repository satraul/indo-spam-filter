{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4\n",
    "## 1606885864 - Ahmad Satryaji Aulia\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Surpress warnings\n",
    "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Do stuff here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import StemmerFactory class\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.csv\")\n",
    "df[\"Message\"] = df[\"Message\"].astype(\"str\")\n",
    "df[\"Mark\"] = df[\"Mark\"].astype(\"str\")\n",
    "dic = pd.read_csv(\"dictionary.csv\")\n",
    "norm = pd.read_csv(\"key_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name       object\n",
       "Mark       object\n",
       "Date       object\n",
       "Message    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Date</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/4/2018 17:33</td>\n",
       "      <td>BAREKSA: Silakan tandatangani FPR di : https:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/4/2018 17:35</td>\n",
       "      <td>Terimakasih. Nomor ini telah terdaftar untuk v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/9/2018 14:24</td>\n",
       "      <td>Mohon maaf transaksi pembelian/penjualan/penga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/10/2018 13:21</td>\n",
       "      <td>Mohon maaf transaksi pembelian/penjualan/penga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>8/7/2018 14:08</td>\n",
       "      <td>Mohon maaf transaksi reksadana Anda di Bareksa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Mark             Date  \\\n",
       "0  Z-SMS  Spam   7/4/2018 17:33   \n",
       "1  Z-SMS  Spam   7/4/2018 17:35   \n",
       "2  Z-SMS  Spam   7/9/2018 14:24   \n",
       "3  Z-SMS  Spam  7/10/2018 13:21   \n",
       "4  Z-SMS  Spam   8/7/2018 14:08   \n",
       "\n",
       "                                             Message  \n",
       "0  BAREKSA: Silakan tandatangani FPR di : https:/...  \n",
       "1  Terimakasih. Nomor ini telah terdaftar untuk v...  \n",
       "2  Mohon maaf transaksi pembelian/penjualan/penga...  \n",
       "3  Mohon maaf transaksi pembelian/penjualan/penga...  \n",
       "4  Mohon maaf transaksi reksadana Anda di Bareksa...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Date</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/4/2018 17:33</td>\n",
       "      <td>BAREKSA Silakan tandatangani FPR di  httpsmbar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/4/2018 17:35</td>\n",
       "      <td>Terimakasih Nomor ini telah terdaftar untuk ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/9/2018 14:24</td>\n",
       "      <td>Mohon maaf transaksi pembelianpenjualanpengali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/10/2018 13:21</td>\n",
       "      <td>Mohon maaf transaksi pembelianpenjualanpengali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>8/7/2018 14:08</td>\n",
       "      <td>Mohon maaf transaksi reksadana Anda di Bareksa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Mark             Date  \\\n",
       "0  Z-SMS  Spam   7/4/2018 17:33   \n",
       "1  Z-SMS  Spam   7/4/2018 17:35   \n",
       "2  Z-SMS  Spam   7/9/2018 14:24   \n",
       "3  Z-SMS  Spam  7/10/2018 13:21   \n",
       "4  Z-SMS  Spam   8/7/2018 14:08   \n",
       "\n",
       "                                             Message  \n",
       "0  BAREKSA Silakan tandatangani FPR di  httpsmbar...  \n",
       "1  Terimakasih Nomor ini telah terdaftar untuk ve...  \n",
       "2  Mohon maaf transaksi pembelianpenjualanpengali...  \n",
       "3  Mohon maaf transaksi pembelianpenjualanpengali...  \n",
       "4  Mohon maaf transaksi reksadana Anda di Bareksa...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punctuation removal\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text) # Remove numbers\n",
    "    return text\n",
    "\n",
    "df[\"Message\"] = df[\"Message\"].apply(lambda x: remove_punct(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Date</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/4/2018 17:33</td>\n",
       "      <td>bareksa silakan tandatangani fpr di httpsmbare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/4/2018 17:35</td>\n",
       "      <td>terimakasih nomor ini telah terdaftar untuk ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/9/2018 14:24</td>\n",
       "      <td>mohon maaf transaksi pembelianpenjualanpengali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/10/2018 13:21</td>\n",
       "      <td>mohon maaf transaksi pembelianpenjualanpengali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>8/7/2018 14:08</td>\n",
       "      <td>mohon maaf transaksi reksadana anda di bareksa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Mark             Date  \\\n",
       "0  Z-SMS  Spam   7/4/2018 17:33   \n",
       "1  Z-SMS  Spam   7/4/2018 17:35   \n",
       "2  Z-SMS  Spam   7/9/2018 14:24   \n",
       "3  Z-SMS  Spam  7/10/2018 13:21   \n",
       "4  Z-SMS  Spam   8/7/2018 14:08   \n",
       "\n",
       "                                             Message  \n",
       "0  bareksa silakan tandatangani fpr di httpsmbare...  \n",
       "1  terimakasih nomor ini telah terdaftar untuk ve...  \n",
       "2  mohon maaf transaksi pembelianpenjualanpengali...  \n",
       "3  mohon maaf transaksi pembelianpenjualanpengali...  \n",
       "4  mohon maaf transaksi reksadana anda di bareksa...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kata tidak baku ke baku\n",
    "norm_dic = pd.Series(norm.hasil.values,index=norm.singkat).to_dict()\n",
    "\n",
    "def replace_norm(text):\n",
    "    text_tokenized = nltk.word_tokenize(text.lower())\n",
    "    text = \" \".join(word if word not in norm_dic else norm_dic[word] for word in text_tokenized)\n",
    "    return text\n",
    "\n",
    "df[\"Message\"] = df[\"Message\"].apply(lambda x: replace_norm(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Date</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/4/2018 17:33</td>\n",
       "      <td>bareksa sila tandatangani fpr di httpsmbareksa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/4/2018 17:35</td>\n",
       "      <td>terimakasih nomor ini telah daftar untuk verif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/9/2018 14:24</td>\n",
       "      <td>mohon maaf transaksi pembelianpenjualanpengali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>7/10/2018 13:21</td>\n",
       "      <td>mohon maaf transaksi pembelianpenjualanpengali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z-SMS</td>\n",
       "      <td>Spam</td>\n",
       "      <td>8/7/2018 14:08</td>\n",
       "      <td>mohon maaf transaksi reksadana anda di bareksa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Mark             Date  \\\n",
       "0  Z-SMS  Spam   7/4/2018 17:33   \n",
       "1  Z-SMS  Spam   7/4/2018 17:35   \n",
       "2  Z-SMS  Spam   7/9/2018 14:24   \n",
       "3  Z-SMS  Spam  7/10/2018 13:21   \n",
       "4  Z-SMS  Spam   8/7/2018 14:08   \n",
       "\n",
       "                                             Message  \n",
       "0  bareksa sila tandatangani fpr di httpsmbareksa...  \n",
       "1  terimakasih nomor ini telah daftar untuk verif...  \n",
       "2  mohon maaf transaksi pembelianpenjualanpengali...  \n",
       "3  mohon maaf transaksi pembelianpenjualanpengali...  \n",
       "4  mohon maaf transaksi reksadana anda di bareksa...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "sf = StemmerFactory()\n",
    "stemmer = sf.create_stemmer()\n",
    "df[\"Message\"] = df[\"Message\"].map(stemmer.stem)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah total vocabulary: 3318\n",
      "Representasi vektor \"promo panjang dapat potong rpbulan total cashback hingga juta hanya di xl prioritas daftar di xl center atau hubung mp\"\n",
      "  (0, 169)\t1\n",
      "  (0, 516)\t1\n",
      "  (0, 528)\t1\n",
      "  (0, 620)\t1\n",
      "  (0, 631)\t1\n",
      "  (0, 687)\t2\n",
      "  (0, 1024)\t1\n",
      "  (0, 1063)\t1\n",
      "  (0, 1192)\t1\n",
      "  (0, 1382)\t1\n",
      "  (0, 1844)\t1\n",
      "  (0, 2057)\t1\n",
      "  (0, 2179)\t1\n",
      "  (0, 2196)\t1\n",
      "  (0, 2208)\t1\n",
      "  (0, 2375)\t1\n",
      "  (0, 2899)\t1\n",
      "  (0, 3223)\t2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Vectorize\n",
    "bow_transformer = CountVectorizer().fit(df[\"Message\"])\n",
    "# print total number of vocab words\n",
    "print(\"Jumlah total vocabulary:\",len(bow_transformer.vocabulary_))\n",
    "# example of vectorized text\n",
    "sample_tweet = df[\"Message\"][50]\n",
    "# Vector representation\n",
    "bow_sample = bow_transformer.transform([sample_tweet])\n",
    "print(\"Representasi vektor \\\"{}\\\"\\n{}\".format(sample_tweet, bow_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words sparse matrix shape:  (3103, 3318)\n",
      "Non zero occurences:  53431\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(df[\"Message\"])\n",
    "# Check out the bag-of-words counts for the entire corpus as a large sparse matrix\n",
    "print('Bag of words sparse matrix shape: ', messages_bow.shape)\n",
    "print('Non zero occurences: ', messages_bow.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3223)\t0.2549637872645276\n",
      "  (0, 2899)\t0.22066971885727155\n",
      "  (0, 2375)\t0.37757436929474997\n",
      "  (0, 2208)\t0.16805447545858374\n",
      "  (0, 2196)\t0.26409754695536053\n",
      "  (0, 2179)\t0.2762145291656409\n",
      "  (0, 2057)\t0.19544599732828602\n",
      "  (0, 1844)\t0.2955068012101702\n",
      "  (0, 1382)\t0.2518879297325356\n",
      "  (0, 1192)\t0.1508623494916039\n",
      "  (0, 1063)\t0.21387460351303852\n",
      "  (0, 1024)\t0.16697727140693125\n",
      "  (0, 687)\t0.19325514234134752\n",
      "  (0, 631)\t0.14986593678225058\n",
      "  (0, 620)\t0.24742045144432445\n",
      "  (0, 528)\t0.2612295572819805\n",
      "  (0, 516)\t0.2787559431371377\n",
      "  (0, 169)\t0.13087216786882247\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf_sample = tfidf_transformer.transform(bow_sample)\n",
    "print(tfidf_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', None), # do not set classifier yet\n",
    "])\n",
    "\n",
    "# Pipeline params for tuning\n",
    "parameters = {'bow__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoost.\n",
      "Running GridSearchCV for Naive Bayes - Bernoulli.\n",
      "Running GridSearchCV for Naive Bayes - Multinomial.\n",
      "Running GridSearchCV for GradientBoosting.\n",
      "Running GridSearchCV for RandomForest.\n",
      "Running GridSearchCV for LogisticRegression.\n",
      "Running GridSearchCV for SVC.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Classifiers\n",
    "clfs = {}\n",
    "clfs[\"AdaBoost\"] = AdaBoostClassifier()\n",
    "clfs[\"Naive Bayes - Bernoulli\"] = BernoulliNB()\n",
    "clfs[\"Naive Bayes - Multinomial\"] = MultinomialNB()\n",
    "clfs[\"GradientBoosting\"] = GradientBoostingClassifier()\n",
    "clfs[\"RandomForest\"] = RandomForestClassifier()\n",
    "clfs[\"LogisticRegression\"] = LogisticRegression()\n",
    "clfs[\"SVC\"] = SVC()\n",
    "\n",
    "grid_searches = {}\n",
    "# Do 10-fold cross validation for each model for each of the 4 possible param combinations\n",
    "for clf in clfs:\n",
    "    print(\"Running GridSearchCV for {}.\".format(clf))\n",
    "    pipeline.set_params(classifier = clfs[clf])\n",
    "    grid = GridSearchCV(pipeline, cv=10, param_grid=parameters)\n",
    "    grid.fit(df[\"Message\"],df[\"Mark\"])\n",
    "    grid_searches[clf] = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>bow__ngram_range</th>\n",
       "      <th>tfidf__use_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.00845128</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.97411</td>\n",
       "      <td>0.984528</td>\n",
       "      <td>0.990354</td>\n",
       "      <td>0.00573905</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.974277</td>\n",
       "      <td>0.984208</td>\n",
       "      <td>0.996785</td>\n",
       "      <td>0.00601236</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.96463</td>\n",
       "      <td>0.980014</td>\n",
       "      <td>0.987138</td>\n",
       "      <td>0.00688718</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.970968</td>\n",
       "      <td>0.976149</td>\n",
       "      <td>0.983923</td>\n",
       "      <td>0.00388496</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.951768</td>\n",
       "      <td>0.976144</td>\n",
       "      <td>0.990323</td>\n",
       "      <td>0.01156</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.954984</td>\n",
       "      <td>0.975825</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.0120776</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.94822</td>\n",
       "      <td>0.971947</td>\n",
       "      <td>0.987138</td>\n",
       "      <td>0.0140992</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.967638</td>\n",
       "      <td>0.971314</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>0.00307664</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.970991</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.00384204</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes - Multinomial</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.967451</td>\n",
       "      <td>0.974277</td>\n",
       "      <td>0.00303108</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes - Bernoulli</td>\n",
       "      <td>0.961415</td>\n",
       "      <td>0.967449</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>0.00419276</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Naive Bayes - Bernoulli</td>\n",
       "      <td>0.961415</td>\n",
       "      <td>0.967449</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>0.00419276</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Naive Bayes - Multinomial</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.96713</td>\n",
       "      <td>0.971061</td>\n",
       "      <td>0.0023935</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.966484</td>\n",
       "      <td>0.974277</td>\n",
       "      <td>0.00295239</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Naive Bayes - Multinomial</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.966162</td>\n",
       "      <td>0.971061</td>\n",
       "      <td>0.00215304</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Naive Bayes - Multinomial</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.966162</td>\n",
       "      <td>0.971061</td>\n",
       "      <td>0.00215304</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Naive Bayes - Bernoulli</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.966162</td>\n",
       "      <td>0.971061</td>\n",
       "      <td>0.00215304</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Naive Bayes - Bernoulli</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.966162</td>\n",
       "      <td>0.971061</td>\n",
       "      <td>0.00215304</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.965197</td>\n",
       "      <td>0.967638</td>\n",
       "      <td>0.00122104</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.965197</td>\n",
       "      <td>0.967638</td>\n",
       "      <td>0.00122104</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.965197</td>\n",
       "      <td>0.967638</td>\n",
       "      <td>0.00122104</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.965197</td>\n",
       "      <td>0.967638</td>\n",
       "      <td>0.00122104</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.92283</td>\n",
       "      <td>0.962603</td>\n",
       "      <td>0.990354</td>\n",
       "      <td>0.0264393</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.765273</td>\n",
       "      <td>0.958132</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.0658496</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.765273</td>\n",
       "      <td>0.95523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0647906</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.55627</td>\n",
       "      <td>0.939817</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.128413</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.55627</td>\n",
       "      <td>0.938525</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.128144</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    estimator min_score mean_score max_score   std_score  \\\n",
       "0                RandomForest  0.970874   0.985816  0.993569  0.00845128   \n",
       "1                RandomForest   0.97411   0.984528  0.990354  0.00573905   \n",
       "2                RandomForest  0.974277   0.984208  0.996785  0.00601236   \n",
       "3                RandomForest   0.96463   0.980014  0.987138  0.00688718   \n",
       "4          LogisticRegression  0.970968   0.976149  0.983923  0.00388496   \n",
       "5            GradientBoosting  0.951768   0.976144  0.990323     0.01156   \n",
       "6            GradientBoosting  0.954984   0.975825  0.993569   0.0120776   \n",
       "7            GradientBoosting   0.94822   0.971947  0.987138   0.0140992   \n",
       "8          LogisticRegression  0.967638   0.971314  0.977492  0.00307664   \n",
       "9          LogisticRegression  0.964516   0.970991  0.980707  0.00384204   \n",
       "10  Naive Bayes - Multinomial  0.964516   0.967451  0.974277  0.00303108   \n",
       "11    Naive Bayes - Bernoulli  0.961415   0.967449  0.977492  0.00419276   \n",
       "12    Naive Bayes - Bernoulli  0.961415   0.967449  0.977492  0.00419276   \n",
       "13  Naive Bayes - Multinomial  0.964516    0.96713  0.971061   0.0023935   \n",
       "14         LogisticRegression  0.964516   0.966484  0.974277  0.00295239   \n",
       "15  Naive Bayes - Multinomial  0.964516   0.966162  0.971061  0.00215304   \n",
       "16  Naive Bayes - Multinomial  0.964516   0.966162  0.971061  0.00215304   \n",
       "17    Naive Bayes - Bernoulli  0.964516   0.966162  0.971061  0.00215304   \n",
       "18    Naive Bayes - Bernoulli  0.964516   0.966162  0.971061  0.00215304   \n",
       "19                        SVC  0.964516   0.965197  0.967638  0.00122104   \n",
       "20                        SVC  0.964516   0.965197  0.967638  0.00122104   \n",
       "21                        SVC  0.964516   0.965197  0.967638  0.00122104   \n",
       "22                        SVC  0.964516   0.965197  0.967638  0.00122104   \n",
       "23           GradientBoosting   0.92283   0.962603  0.990354   0.0264393   \n",
       "24                   AdaBoost  0.765273   0.958132  0.996774   0.0658496   \n",
       "25                   AdaBoost  0.765273    0.95523         1   0.0647906   \n",
       "26                   AdaBoost   0.55627   0.939817  0.996774    0.128413   \n",
       "27                   AdaBoost   0.55627   0.938525  0.993569    0.128144   \n",
       "\n",
       "   bow__ngram_range tfidf__use_idf  \n",
       "0            (1, 1)          False  \n",
       "1            (1, 1)           True  \n",
       "2            (1, 2)           True  \n",
       "3            (1, 2)          False  \n",
       "4            (1, 1)          False  \n",
       "5            (1, 1)          False  \n",
       "6            (1, 1)           True  \n",
       "7            (1, 2)          False  \n",
       "8            (1, 2)          False  \n",
       "9            (1, 1)           True  \n",
       "10           (1, 1)           True  \n",
       "11           (1, 1)           True  \n",
       "12           (1, 1)          False  \n",
       "13           (1, 1)          False  \n",
       "14           (1, 2)           True  \n",
       "15           (1, 2)          False  \n",
       "16           (1, 2)           True  \n",
       "17           (1, 2)          False  \n",
       "18           (1, 2)           True  \n",
       "19           (1, 1)           True  \n",
       "20           (1, 1)          False  \n",
       "21           (1, 2)           True  \n",
       "22           (1, 2)          False  \n",
       "23           (1, 2)           True  \n",
       "24           (1, 1)          False  \n",
       "25           (1, 2)          False  \n",
       "26           (1, 1)           True  \n",
       "27           (1, 2)           True  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_summary(grid_searches, sort_by='mean_score'):\n",
    "    def row(key, scores, params):\n",
    "        d = {\n",
    "             'estimator': key,\n",
    "             'min_score': min(scores),\n",
    "             'max_score': max(scores),\n",
    "             'mean_score': np.mean(scores),\n",
    "             'std_score': np.std(scores),\n",
    "        }\n",
    "        return pd.Series({**params,**d})\n",
    "\n",
    "    rows = []\n",
    "    for k in grid_searches:\n",
    "        params = grid_searches[k].cv_results_['params']\n",
    "        scores = []\n",
    "        for i in range(grid_searches[k].cv):\n",
    "            key = \"split{}_test_score\".format(i)\n",
    "            r = grid_searches[k].cv_results_[key]        \n",
    "            scores.append(r.reshape(len(params),1))\n",
    "\n",
    "        all_scores = np.hstack(scores)\n",
    "        for p, s in zip(params,all_scores):\n",
    "            rows.append((row(k, s, p)))\n",
    "\n",
    "    df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "    columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "    columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "    return df[columns]\n",
    "\n",
    "score_summary(grid_searches).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
